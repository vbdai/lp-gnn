{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Initial Basis Selection for Linear Programs\n",
    "\n",
    "This notebook demonstrate a GNN-based smart initial basis selection method, a novel algorithm developed by Vancouver Big Data and Intelligence Lab, Huawei Canada. \n",
    "\n",
    "## Overview \n",
    "\n",
    "- Background: Companies or large organizations often need to repeatedly solve similar linear programming (LP) problems, such as scheduling a large number of flights per hour at an airport.\n",
    "- Problem Definition: Given a set of historical LPs and a similar test LP, the goal is to predict the initial basis for the test LP that allows the simplex algorithm to converge faster starting from that basis.\n",
    "\n",
    "    - Consider the following standard form of LP: $$\\begin{align*}\n",
    "\\text{Minimize } & c^T x \\\\\n",
    "\\text{Subject to:} \\\\\n",
    "& Ax = s \\\\\n",
    "& l^x \\leq x \\leq u^x \\\\\n",
    "& l^s \\leq s \\leq u^s\n",
    "\\end{align*}$$\n",
    "\n",
    "    - Note: Lower bounds $l^x$, $l^s$ can be $-\\infty$, and upper bounds $u^x$, $u^s$ can be $\\infty$.\n",
    "\n",
    "- Algorithm Steps:\n",
    "\n",
    "    - Represent the LP as a bipartite graph and design features for each variable and constraint.\n",
    "    - Build a training set using historical LPs and train a two-layer graph neural network.\n",
    "    - Use knowledge masking to resolve conflicts between the predicted basis by the graph network and the variable bounds.\n",
    "    - Generate and adjust the initial basis to ensure compliance with the rules of a valid basis.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- This demo is tested with Ubuntu 20.04, Python(>=3.8 & <=3.10), PyTorch(>=1.8 & <=1.10) and HiGHS 1.3.1, and are generalizable to other linux system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://modelarts-cnnorth1-market-dataset.obs.cn-north-1.myhuaweicloud.com/example-apps/LP-GNN/code.zip \n",
    "!unzip -qo code.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "## setup for network if needed \n",
    "# os.environ['http_proxy']=os.environ['https_proxy']=\"http://127.0.0.1:3128\"\n",
    "# os.environ['home']='/home/xinglu/' \n",
    "\n",
    "## The most recommened way is through conda\n",
    "## because compiling pytorch-sparse from source code fails if libarary is missing or gcc version mismatch\n",
    "## Note: change to pytorch with GPU if needed\n",
    "!conda install pytorch-sparse==0.6.12 pytorch-scatter pytorch cpuonly -c pytorch -c pyg -y\n",
    "!pip install \"torch_geometric==2.1\"\n",
    "## If conda failed, try install with pip with following:\n",
    "# !pip install torch==1.8.0\n",
    "# import re\n",
    "# pv = !python --version\n",
    "# version_string=pv[0] \n",
    "# major_version = re.search(r'(\\d+)\\.', version_string).group(1)\n",
    "# minor_version = re.search(r'\\.(\\d+)\\.', version_string).group(1)\n",
    "# vsm=vs=f\"{major_version}{minor_version}\"\n",
    "# if vs=='37': vsm=vs+'m'\n",
    "# !rm -rf *.whl *.whl.*\n",
    "# url=f\"https://data.pyg.org/whl/torch-1.8.0%2Bcpu/torch_sparse-0.6.12-cp{vs}-cp{vsm}-linux_x86_64.whl\"\n",
    "# !wget $url --no-check-certificate\n",
    "# url=f\"https://data.pyg.org/whl/torch-1.8.0%2Bcpu/torch_scatter-2.0.8-cp{vs}-cp{vsm}-linux_x86_64.whl\"\n",
    "# !wget $url --no-check-certificate\n",
    "# !pip install ./*.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install pandas numpy\n",
    "!pip install mip tables \n",
    "!pip install colorlog msgpack msgpack_numpy tensorboard easydict seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "## Before starting to train and test, the experiment folder `highs--mirp-balance-ep800-archGCN_FC-8-8-hids-1024-depth-3` for `mirp` is uploaded under runs, we can extract and show the performance\n",
    "exp_nm=\"highs--mirp-balance-ep800-archGCN_FC-8-8-hids-1024-depth-3\"\n",
    "!python scripts/extract_time.py --exp_nm $exp_nm\n",
    "\n",
    "import torch_geometric\n",
    "import numpy as np \n",
    "from utils import df_load, check_df, filter_cols, proc\n",
    "\n",
    "df=df_load(f\"runs/{exp_nm}/time.h5\")\n",
    "df=df[df.split=='val']\n",
    "if df.isnull().any().any(): print('warn: ori contain nan')\n",
    "df.index=df.fn\n",
    "check_vals=[np.inf,-1,-2,-3]\n",
    "for check_val in check_vals:\n",
    "    if check_df(df,check_val).shape[0]!=0: print('warn: table contains errorcode', check_val)  \n",
    "df=df.replace(check_vals,np.nan)  \n",
    "dft=df.describe().loc[['mean','std']]\n",
    "use_method=f'gnn-bas-0'\n",
    "cs=filter_cols([\n",
    "            f'highs-no-bas/niter', f'highs-ca-bas/niter', f'{use_method}/niter',            \n",
    "            ], df.columns)\n",
    "res=dft[cs].apply(proc, axis=0).to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>highs-no-bas/niter</th>\n",
       "      <th>highs-ca-bas/niter</th>\n",
       "      <th>gnn-bas-0/niter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$29.9K{\\scriptscriptstyle  \\pm 17.0K}$</td>\n",
       "      <td>$26.2K{\\scriptscriptstyle  \\pm 14.2K}$</td>\n",
       "      <td>$17.4K{\\scriptscriptstyle  \\pm 11.0K}$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       highs-no-bas/niter   \n",
       "0  $29.9K{\\scriptscriptstyle  \\pm 17.0K}$  \\\n",
       "\n",
       "                       highs-ca-bas/niter   \n",
       "0  $26.2K{\\scriptscriptstyle  \\pm 14.2K}$  \\\n",
       "\n",
       "                          gnn-bas-0/niter  \n",
       "0  $17.4K{\\scriptscriptstyle  \\pm 11.0K}$  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "## Compile and Install HiGHS (https://ergo-code.github.io/HiGHS/get-started). Add the path contain exective `highs` to system enviroment variable PATH. \n",
    "## We cutomized the HiGHS code such that the log file contains more information. This part code comes with this notebook. \n",
    "## Ubuntu 20.04 pairs with g++ 9.4 and cmake 3.16. Make sure cmake and g++ are installed, e.g., via apt on Ubuntu. \n",
    "!cd HiGHS-master&&mkdir build -p&&cd build&&cmake .. && make -j10 \n",
    "cur=%pwd\n",
    "PATH=os.environ['PATH']\n",
    "os.environ['PATH']=f\"{cur}/HiGHS-master/build/bin:{PATH}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## double check that highs is successfully installed\n",
    "!highs -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: data preparation\n",
    "\n",
    "- `python run_prep_data.py` will prepare the dataset, including running Simplex algorithm, saving the log, and serialize the dataset for training. \n",
    "    - In this demo we use mirp dataset from https://mirplib.scl.gatech.edu/ (Group 1, https://mirplib.scl.gatech.edu/sites/default/files/Group1_MPS_files.zip), which already comes with this demo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_prep_data.py --dataset mirp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Step 2: train GNN model\n",
    "\n",
    "We can use `run_train_test.py` (the end-to-end script) for train and test, but we will do it step by step. \n",
    "\n",
    "`train.py` will save the GNN model to exp_folder/mdl.pth. It spends a long time for training. For demonstration, `mdl.pth` is uploaded under `runs/highs--mirp-balance-ep800-archGCN_FC-8-8-hids-1024-depth-3`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## skip this if do not want to training\n",
    "# !python train.py --arch 'GCN_FC(8,8,hids=1024,depth=3)' --epochs 800 --loss balanced --exp_nm a_new_exp_folder --dataset mirp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: evaluate GNN model and its predicted basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict the basis with GNN model, we will use the uploaded checkpoint.\n",
    "!python scripts/pred_basis.py --arch 'GCN_FC(8,8,hids=1024,depth=3)' --exp_nm $exp_nm --load_from runs/$exp_nm/mdl.pth --dataset mirp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run solver with predicted initial basis \n",
    "!python scripts/run_solver_from_basis.py --num_workers 1 --lp_method 1 --dataset mirp --exp_nm $exp_nm \n",
    "## report the final performance \n",
    "!python scripts/extract_time.py --exp_nm $exp_nm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tidy up before release the demo\n",
    "!rm -rf ./HiGHS-master/build __pycache__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d1c7023394c1a8c116755aeb1d6847c572ab65b1e938842fc25a82a216b952ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
